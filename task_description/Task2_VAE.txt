Assignment - Final - Task 2 - VAE
=================================

Please refer to ReadMe.txt for general rules for this final assignment.

In this task, you shall train a Variational Autoencoder (VAE) to generate data similar to the training set.

You shall use the provided code to generate your train and test data.
Keep the images small - 32 pixels - with a single object of one of the four categories with max size 24 pixels.
You can generate as many examples for the training set as you wish (10000 may be a good number).
For testset generate 100 examples.

You shall implement and train two models: a standard autoencoder (AE) and a variational autoencoder (VAE). 
These models shall have the same architecture and size of the latent bottleneck.
However, they shall be trained differently by using the appropriate loss.
The architecture can be fairly simple, do not go for too complicated models.

You shall follow the instructions for the content of the report as explained in ReadMe.txt. 
In addition, for both models - AE and VAE - you shall use the final trained versions to:
* Report the test reconstruction loss (average l2 distance between original and reconstructed images)
* Print 10 examples of original test images and their reconstructions
* Print 10 examples of images generated by the decoder when starting from random latent vectors.
* Compare the results for AE and VAE, and discuss the results.

References: 
* Kingma, D. P., & Welling, M. (2019). An introduction to variational autoencoders. Foundations and Trends® in Machine Learning, 12(4), 307-392.
* Kingma, D. P. and Welling, M., “An Introduction to Variational Autoencoders”, <i>arXiv e-prints</i>, 2019. doi:10.48550/arXiv.1906.02691.
* Tutorials, blogs etc. online


